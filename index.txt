1:"$Sreact.fragment"
2:I[3719,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-627ef85ed6aeb379.js"],"ThemeProvider"]
3:I[768,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-627ef85ed6aeb379.js"],"default"]
4:I[7555,[],""]
5:I[1295,[],""]
6:I[2548,["17","static/chunks/17-9c04c9413a9f9f1f.js","874","static/chunks/874-6cc630662f3664af.js","862","static/chunks/862-15038af301665bb3.js","177","static/chunks/app/layout-627ef85ed6aeb379.js"],"default"]
7:I[7437,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-4648f213a193e836.js"],"default"]
8:I[9507,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-4648f213a193e836.js"],"default"]
9:I[5218,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-4648f213a193e836.js"],"default"]
c:I[2630,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-4648f213a193e836.js"],"default"]
d:I[1990,["17","static/chunks/17-9c04c9413a9f9f1f.js","178","static/chunks/178-595a94b9af1e67b5.js","874","static/chunks/874-6cc630662f3664af.js","748","static/chunks/748-1f3129a1e6365cf9.js","974","static/chunks/app/page-4648f213a193e836.js"],"default"]
e:I[9665,[],"MetadataBoundary"]
10:I[9665,[],"OutletBoundary"]
13:I[4911,[],"AsyncMetadataOutlet"]
15:I[9665,[],"ViewportBoundary"]
17:I[6614,[],""]
:HL["/_next/static/css/8bb526581b756a19.css","style"]
a:T4f1,Short text classification task poses challenges in natural language processing due to insufficient contextual information. This task is typically approached by extracting rich semantic features in the text and encoding it as a sentence-level representation using deep neural networks. The self-attention mechanism has emerged as one of the primary methods to tackle this problem. However, traditional attention methods only focus on the interactions between tokens, neglecting the semantic relationships between features. We propose a novel attention-based module, called token-feature woven attention fusion (TFWAF) network for sentence-level representation information aggregation, which leverages the self-attention mechanism from both token and feature perspectives. Moreover, we design a multi-schema prompting approach within machine reading comprehension and prompt learning paradigms to better utilize prior knowledge in a pre-trained language model and recognize enhanced textual semantic representation. Experimental results show our model achieves state-of-the-art performance compared to existing baselines on eight benchmark datasets in the context of short text classification. The source code is available in https://github.com/Aaronzijingcai/MP-TFWAb:T6a0,@article{cai2024multi,
  title = {Multi-schema prompting powered token-feature woven attention network for short text classification},
  author = {Cai, Zijing and Zhang, Hua and Zhan, Peiqian and Jia, Xiaohui and Yan, Yongjian and Song, Xiawen and Xie, Bo},
  journal = {Pattern Recognition},
  volume = {156},
  pages = {110782},
  year = {2024},
  publisher = {Elsevier},
  abstract = {Short text classification task poses challenges in natural language processing due to insufficient contextual information. This task is typically approached by extracting rich semantic features in the text and encoding it as a sentence-level representation using deep neural networks. The self-attention mechanism has emerged as one of the primary methods to tackle this problem. However, traditional attention methods only focus on the interactions between tokens, neglecting the semantic relationships between features. We propose a novel attention-based module, called token-feature woven attention fusion (TFWAF) network for sentence-level representation information aggregation, which leverages the self-attention mechanism from both token and feature perspectives. Moreover, we design a multi-schema prompting approach within machine reading comprehension and prompt learning paradigms to better utilize prior knowledge in a pre-trained language model and recognize enhanced textual semantic representation. Experimental results show our model achieves state-of-the-art performance compared to existing baselines on eight benchmark datasets in the context of short text classification. The source code is available in https://github.com/Aaronzijingcai/MP-TFWA},
  doi = {10.1016/j.patcog.2024.110782}
}0:{"P":null,"b":"u0-iT8ieP_hvHQ4Jd7GEV","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/8bb526581b756a19.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","className":"scroll-smooth","suppressHydrationWarning":true,"children":[["$","head",null,{"children":[["$","link",null,{"rel":"icon","href":"/favicon.svg","type":"image/svg+xml"}],["$","link",null,{"rel":"dns-prefetch","href":"https://google-fonts.jialeliu.com"}],["$","link",null,{"rel":"preconnect","href":"https://google-fonts.jialeliu.com","crossOrigin":""}],["$","link",null,{"rel":"preload","as":"style","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}],["$","link",null,{"rel":"stylesheet","id":"gfonts-css","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap","media":"print"}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              (function(){\n                var l = document.getElementById('gfonts-css');\n                if (!l) return;\n                if (l.media !== 'all') {\n                  l.addEventListener('load', function(){ try { l.media = 'all'; } catch(e){} });\n                }\n              })();\n            "}}],["$","noscript",null,{"children":["$","link",null,{"rel":"stylesheet","href":"https://google-fonts.jialeliu.com/css2?family=Inter:wght@300;400;500;600;700&family=Crimson+Text:ital,wght@0,400;0,600;1,400&display=swap"}]}],["$","script",null,{"dangerouslySetInnerHTML":{"__html":"\n              try {\n                const theme = localStorage.getItem('theme-storage');\n                const parsed = theme ? JSON.parse(theme) : null;\n                const setting = parsed?.state?.theme || 'system';\n                const prefersDark = typeof window !== 'undefined' && window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches;\n                const effective = setting === 'dark' ? 'dark' : (setting === 'light' ? 'light' : (prefersDark ? 'dark' : 'light'));\n                var root = document.documentElement;\n                root.classList.add(effective);\n                root.setAttribute('data-theme', effective);\n              } catch (e) {\n                var root = document.documentElement;\n                root.classList.add('light');\n                root.setAttribute('data-theme', 'light');\n              }\n            "}}]]}],["$","body",null,{"className":"font-sans antialiased","children":["$","$L2",null,{"children":[["$","$L3",null,{"items":[{"title":"About","type":"page","target":"about","href":"/"},{"title":"Publications","type":"page","target":"publications","href":"/publications"},{"title":"Internship","type":"page","target":"internship","href":"/internship"},{"title":"Awards","type":"page","target":"awards","href":"/awards"},{"title":"Services","type":"page","target":"services","href":"/services"},{"title":"CV","type":"page","target":"cv","href":"/cv"}],"siteTitle":"Zijing Cai","enableOnePageMode":false}],["$","main",null,{"className":"min-h-screen pt-16 lg:pt-20","children":["$","$L4",null,{"parallelRouterKey":"children","error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],[]],"forbidden":"$undefined","unauthorized":"$undefined"}]}],["$","$L6",null,{"lastUpdated":"November 27, 2025"}]]}]}]]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","div",null,{"className":"max-w-6xl mx-auto px-4 sm:px-6 lg:px-8 py-8 bg-background min-h-screen","children":["$","div",null,{"className":"grid grid-cols-1 lg:grid-cols-3 gap-12","children":[["$","div",null,{"className":"lg:col-span-1","children":["$","$L7",null,{"author":{"name":"Zijing Cai","title":"M.Eng. Student","institution":"USTC","avatar":"/bio.jpg"},"social":{"email":"aaron.zijingcai@gmail.com","location":"HeFei, China","location_url":"https://maps.google.com","location_details":["100, Fuxing Road"],"google_scholar":"https://scholar.google.com/citations?user=m-_Wth8AAAAJ&hl=zh-CN","orcid":"https://orcid.org/0009-0005-6691-7908","github":"https://github.com/Aaronzijingcai","linkedin":"https://www.linkedin.com/in/zijing-cai-4ba93237a/"},"features":{"enable_likes":true,"enable_one_page_mode":false},"researchInterests":["Visual Document Retrieval","Multimodal Large Model","Continual Learning"]}]}],["$","div",null,{"className":"lg:col-span-2 space-y-8","children":[["$","section","about",{"id":"about","className":"scroll-mt-24 space-y-8","children":[[["$","$L8","about",{"content":"I am a Master student at the School of Artificial Intelligence and Data Science, University of Science and Technology of China, advised by [Prof. Fuli Feng](https://fulifeng.github.io/) and [Prof. Fengbin Zhu(NUS)](https://fengbinzhu.github.io/).\n\nPrior to this, I obtained a BSc degree from the Zhejiang Gongshang University, advised by [Prof. Hua Zhang](https://mypage.zjgsu.edu.cn/scie/zh2/main.htm).\n\nMy current research focuses on investigating the Visual Document Retrieval and Multi-modal Large Model.\n\nWhat I can not create, I do not understand.","title":"About"}],["$","$L9","featured_publications",{"publications":[{"id":"cai2024multi","title":"Multi-schema prompting powered token-feature woven attention network for short text classification","authors":[{"name":"Zijing Cai","isHighlighted":true,"isCorresponding":false,"isCoAuthor":false},{"name":"Hua Zhang","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Peiqian Zhan","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiaohui Jia","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Yongjian Yan","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Xiawen Song","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false},{"name":"Bo Xie","isHighlighted":false,"isCorresponding":false,"isCoAuthor":false}],"year":2024,"type":"journal","status":"published","tags":[],"keywords":"$0:f:0:1:2:children:1:props:children:0:props:children:props:children:1:props:children:0:props:children:0:1:props:publications:0:tags","researchArea":"transformer-architectures","journal":"Pattern Recognition","conference":"","volume":"156","pages":"110782","doi":"10.1016/j.patcog.2024.110782","code":"https://github.com/Aaronzijingcai/MP-TFWA","abstract":"$a","description":"","selected":true,"preview":"TFWAF.png","bibtex":"$b"}],"title":"Selected Publications","enableOnePageMode":true}],["$","$Lc","education",{"items":[{"university":"University of Science and Technology of China","degree":"M.Eng. in Electronic and Information Engineering","period":"Sept. 2025 - Present","logo":"/edu-ustc.png"},{"university":"Zhejiang Gongshang University","degree":"B.Sc. in Software Engineering","period":"Sept. 2020 - June 2024","logo":"/edu-zjgsu.png"}],"title":"Education"}],["$","$Ld","news",{"items":[{"date":"2025-09","content":"Starting my M.Eng. at the University of Science and Technology of China ðŸ‡¨ðŸ‡³"},{"date":"2024-07","content":"Our work MP-TFWA has been accepted by PR 2024 ðŸŽ‰"}],"title":"News"}]],false,false,false]}]]}]]}]}],["$","$Le",null,{"children":"$Lf"}],null,["$","$L10",null,{"children":["$L11","$L12",["$","$L13",null,{"promise":"$@14"}]]}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","s1AH-K_sUBm4311Ka6b3V",{"children":[["$","$L15",null,{"children":"$L16"}],null]}],null]}],false]],"m":"$undefined","G":["$17","$undefined"],"s":false,"S":true}
18:"$Sreact.suspense"
19:I[4911,[],"AsyncMetadata"]
f:["$","$18",null,{"fallback":null,"children":["$","$L19",null,{"promise":"$@1a"}]}]
12:null
16:[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
11:null
1a:{"metadata":[["$","title","0",{"children":"Zijing Cai"}],["$","meta","1",{"name":"description","content":"M.Eng. student at the USTC."}],["$","meta","2",{"name":"author","content":"Zijing Cai"}],["$","meta","3",{"name":"keywords","content":"Zijing Cai,PhD,Research,USTC"}],["$","meta","4",{"name":"creator","content":"Zijing Cai"}],["$","meta","5",{"name":"publisher","content":"Zijing Cai"}],["$","meta","6",{"property":"og:title","content":"Zijing Cai"}],["$","meta","7",{"property":"og:description","content":"M.Eng. student at the USTC."}],["$","meta","8",{"property":"og:site_name","content":"Zijing Cai's Academic Website"}],["$","meta","9",{"property":"og:locale","content":"en_US"}],["$","meta","10",{"property":"og:type","content":"website"}],["$","meta","11",{"name":"twitter:card","content":"summary"}],["$","meta","12",{"name":"twitter:title","content":"Zijing Cai"}],["$","meta","13",{"name":"twitter:description","content":"M.Eng. student at the USTC."}],["$","link","14",{"rel":"icon","href":"/favicon.svg"}]],"error":null,"digest":"$undefined"}
14:{"metadata":"$1a:metadata","error":null,"digest":"$undefined"}
