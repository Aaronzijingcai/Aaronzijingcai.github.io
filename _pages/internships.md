---
layout: archive
title: "Internships"
permalink: /internships/
author_profile: true
---

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:0;margin-left:0;font-size:1.0em;">
    <tbody>
        <tr>
            <td style="padding:8px;width:30%;vertical-align:middle;border:none;"> 
                <img src="https://github.com/Aaronzijingcai/Aaronzijingcai.github.io/raw/master/images/microsoft.png" width="200">
            </td>


            <td style="padding:20px;width:70%;vertical-align:middle;border-right:none;border:none;">
                <b><a href="http://dev3.noahlab.com.hk/index.html">MSRA Shanghai Research Group</a></b>
                <br>
                <b>Research Intern</b>
                <br>
                <b>Apr. 2024 -- Sept. 2024, Shang Hai</b>
                <br>
                <b>Mentored by <a href="">Dr. Zhang</a></b>
            </td>            
        </tr>
    </tbody>

</table>

<!--

## **Research Intern**

_**([MSRA Shanghai Research Group](), Shanghai, Apr. 2024 - Sept. 2024)**_
_**, mentored by [Dr. Zhang]()**_
-->

* Dual Learning of LLMs: utilizing the primal-dual structure between machine learning tasks to obtain effective feedback/regularization, guiding and reinforcing the learning process, thereby reducing the requirements for large-scale learning.

